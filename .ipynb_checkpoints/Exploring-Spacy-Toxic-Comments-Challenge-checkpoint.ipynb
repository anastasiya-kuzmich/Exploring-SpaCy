{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9ebeba",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Importing-packages-&amp;-dataset\" data-toc-modified-id=\"Importing-packages-&amp;-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Importing packages &amp; dataset</a></span></li><li><span><a href=\"#Exploring-the-dataset\" data-toc-modified-id=\"Exploring-the-dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Exploring the dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#General-features\" data-toc-modified-id=\"General-features-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>General features</a></span></li><li><span><a href=\"#Getting-to-know-the-labels\" data-toc-modified-id=\"Getting-to-know-the-labels-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Getting to know the labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#Can-a-comment-be-both-toxic-and-severely-toxic?\" data-toc-modified-id=\"Can-a-comment-be-both-toxic-and-severely-toxic?-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Can a comment be both toxic and severely toxic?</a></span></li><li><span><a href=\"#Do-the-obsene/threat/insult/identity_hate-tags-come-under-the-toxic-umbrella?\" data-toc-modified-id=\"Do-the-obsene/threat/insult/identity_hate-tags-come-under-the-toxic-umbrella?-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Do the obsene/threat/insult/identity_hate tags come under the toxic umbrella?</a></span></li><li><span><a href=\"#Adding-a-non-toxic-column:\" data-toc-modified-id=\"Adding-a-non-toxic-column:-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Adding a non-toxic column:</a></span></li><li><span><a href=\"#Removing-the-total_score-column\" data-toc-modified-id=\"Removing-the-total_score-column-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Removing the total_score column</a></span></li></ul></li></ul></li><li><span><a href=\"#Pre-Modelling:-spaCy\" data-toc-modified-id=\"Pre-Modelling:-spaCy-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Pre-Modelling: spaCy</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe19cc",
   "metadata": {},
   "source": [
    "# Exploring spaCy: Toxicity Levels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e2a5a",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "Using the SpaCy package to explore the [Toxic Comment Classification Challenge](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview). \n",
    "\n",
    "- Challenge: build a model that’s capable of detecting different types of of toxicity like **threats, obscenity, insults, and identity-based hate**. \n",
    "- The dataset contains comments from Wikipedia’s talk page edits. \n",
    "- The goal is to help online discussion become more productive and respectful.\n",
    "\n",
    "**Dataset Description**\n",
    "\n",
    "A large number of Wikipedia comments which have been labeled by human raters for toxic behavior. \n",
    "The types of toxicity are:\n",
    "\n",
    "- toxic\n",
    "- severe_toxic\n",
    "- obscene\n",
    "- threat\n",
    "- insult\n",
    "- identity_hate\n",
    "\n",
    "You must create a model which predicts a **probability of each type of toxicity** for each comment.\n",
    "\n",
    "**File descriptions**\n",
    "\n",
    "- train.csv - the training set, contains comments with their binary labels\n",
    "- test.csv - the test set, you must predict the toxicity probabilities for these comments.\n",
    "- sample_submission.csv - a sample submission file in the correct format\n",
    "- test_labels.csv - labels for the test data; value of -1 indicates it was not used for scoring; (Note: file added after competition close!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bef354",
   "metadata": {},
   "source": [
    "## Importing packages & dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dffff7c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:51:53.261015Z",
     "start_time": "2022-12-20T15:51:51.112574Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set(font_scale=1.5)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a82cb910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:58:41.051585Z",
     "start_time": "2022-12-20T15:58:40.129553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 159571 entries with 8 features.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/anastasiakuzmich/Desktop/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "\n",
    "print(\"The dataset contains %s entries with %s features.\" \n",
    "      % (df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d366e9",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ccc41c",
   "metadata": {},
   "source": [
    "### General features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257b9473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T15:58:16.011286Z",
     "start_time": "2022-12-20T15:58:15.963006Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129a454",
   "metadata": {},
   "source": [
    "✏️ Okay, there's no missing values & the data types are fine. Within this dataset there is:\n",
    "\n",
    "1. An id column which might just be easier to drop. \n",
    "2. The comment_text column which contains the content of the comment itself\n",
    "3. The columns indicating the comment's annotation as toxic, severe_toxic, obscene, threat, insult or identity hate. Let's explore these further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aba66928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T16:02:13.145131Z",
     "start_time": "2022-12-20T16:02:13.092169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb210a8",
   "metadata": {},
   "source": [
    "✏️ The labels are binary, so a comment is either of that label, or not of that label. 9% of the comments are toxic, 5% are obscene, 4% are insults, less than 1% are severely toxic, identity theft or a threat. \n",
    "\n",
    "Let's find out if these labels are are mutually exclusive + how many non-toxic comments there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1262ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T16:10:20.633421Z",
     "start_time": "2022-12-20T16:10:20.617652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.039857\n",
       "3    0.026377\n",
       "2    0.021808\n",
       "4    0.011030\n",
       "5    0.002413\n",
       "6    0.000194\n",
       "Name: total_score, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_score'] = (df['toxic'] \n",
    "                     + df[\"severe_toxic\"] \n",
    "                     + df[\"obscene\"] \n",
    "                     + df[\"threat\"]\n",
    "                     + df[\"insult\"]\n",
    "                     + df[\"identity_hate\"])\n",
    "\n",
    "df['total_score'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a9906",
   "metadata": {},
   "source": [
    "✏️ My takeaways at this stage:\n",
    "\n",
    "- 90% of the comments aren't negative. That's good to know, but we are dealing with severe class imbalance...\n",
    "- A good amount of comments ticks several boxes, so the labels are not exclusive. Some tick all 6 somehow? (*How angry do you have to be?*)\n",
    "- The model needs to be capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate. I need to think about how I'll need to restructure the data and what I want my predictors to be.\n",
    "\n",
    "**Next questions to address:**\n",
    "\n",
    "1. Can a comment be both toxic and severely toxic? \n",
    "2. Are toxic & severe toxic the umbrella categories, then obsene/threat/insult/identity_hate their sub-categories? Restructure and see.\n",
    "3. Perhaps at this stage it is worth introducing a non-toxic column? So the model would almost predict whether the comments are toxic vs non-toxic vs severely toxic, then *if* it's toxic then what subcategory of toxic?\n",
    "\n",
    "### Getting to know the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9c86d",
   "metadata": {},
   "source": [
    "#### Can a comment be both toxic and severely toxic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52acc279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T16:28:14.420885Z",
     "start_time": "2022-12-20T16:28:14.404722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of toxic comments: 15294\n",
      "Number of severely toxic comments: 1595\n",
      "Number of severely toxic and toxic comments: 1595\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of toxic comments:\", len(df[df['toxic'] == 1]))\n",
    "print(\"Number of severely toxic comments:\", len(df[df['severe_toxic'] == 1]))\n",
    "print(\"Number of severely toxic and toxic comments:\", len(df[(df['toxic'] == 1) & (df['severe_toxic'] == 1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e4b26a",
   "metadata": {},
   "source": [
    "✏️ Yes. All severely toxic comments are also toxic, but not all toxic comments are severe. Perhaps it's worth making them exclusive within the dataframe? Could also do it later on after modelling to see if it would improve the score. \n",
    "\n",
    "#### Do the obsene/threat/insult/identity_hate tags come under the toxic umbrella?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12c69bcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T16:37:08.224258Z",
     "start_time": "2022-12-20T16:37:08.204155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obsene comments that are not toxic: 523\n",
      "Number of threatening comments that are not toxic: 29\n",
      "Number of insulting comments that are not toxic: 533\n",
      "Number of identity-hateful comments that are not toxic: 103\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of obsene comments that are not toxic:\",\n",
    "      len(df[(df['toxic'] == 0) & (df['obscene'] == 1)]))\n",
    "\n",
    "print(\"Number of threatening comments that are not toxic:\",\n",
    "      len(df[(df['toxic'] == 0) & (df['threat'] == 1)]))\n",
    "\n",
    "print(\"Number of insulting comments that are not toxic:\",\n",
    "      len(df[(df['toxic'] == 0) & (df['insult'] == 1)]))\n",
    "\n",
    "print(\"Number of identity-hateful comments that are not toxic:\",\n",
    "      len(df[(df['toxic'] == 0) & (df['identity_hate'] == 1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff83f9",
   "metadata": {},
   "source": [
    "✏️ No, apparently they can be mutually exclusive? Which doesn't make complete sense to me. Let's inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b29fdb9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T16:50:51.975225Z",
     "start_time": "2022-12-20T16:50:51.940046Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment  1 :  obscene \n",
      " How do you know he is dead.  Its just his plane that crashed.  Jeezz, quit busting his nuts, folks. \n",
      "\n",
      "Comment  2 :  obscene \n",
      " Bleh. I'm all out of ideas. Is there really something wrong with the server or what? The damn thing won't work for me, either Helvetica_font_new.svg (my upload of Segoe UI was actually a PNG to begin with...) \n",
      "\n",
      "Comment  1 :  threat \n",
      " Please stop. If you continue to ignore our policies by introducing inappropriate pages to Wikipedia, you will be blocked. \n",
      "\n",
      "Comment  2 :  threat \n",
      " \"\n",
      "\n",
      " Lock Down \n",
      "\n",
      "I don't know about the \"\"Bulgarian BULLSHIT season\"\", but don't be fooled from where exactly i connect. If i see you editing, or someone else you send, the DDA40X article one more time, you will spend the next few years in prison. I will arrange you a meeting with certain people for suspicions of terrorism. Yes. I can do that. A terror suspect nowadays, you can kiss your young life goodbye. If you file complaints and i'm banned, you and your naked ass will have the whole time in the world, in the cell block, to think what went wrong. 87.252.167.254  \" \n",
      "\n",
      "Comment  1 :  insult \n",
      " REPLY ABOVE:\n",
      "That was me, loser. The UN defines Vietnam to be part of Southeast Asia. And far as I know Vietnam is part of ASEAN, and used to be part of French Indochina with Laos and all those shit countries Anyway your culture has always been more influenced by SEA than Han Chinese (as in proper Yangtze Han Chinese, not the fringe indigenous tribes in Guangzhou/Guangxi). \n",
      "\n",
      "Just admit that you vietnamese are all a bunch of wannabe crap people. ALL the east asian people I've spoken to thinks of Vietnam as a very integral part of SEA, and we all think you're backward, dirty and speak in a horrible swearing language. Doesn't matter what crap you spout on Wikipedia, won't change the way people in the real world think. \n",
      "\n",
      "Comment  2 :  insult \n",
      " Hebrew Name of Lydia \n",
      "Appologies to Til Eulenspiegel I thought you were one of the idiots which your user page indicates you actually do well struggling against. \n",
      "Genesis 10:יג  וּמִצְרַיִם יָלַד אֶת-לוּדִים וְאֶת-עֲנָמִים, וְאֶת-לְהָבִיםוְאֶת-נַפְתֻּחִים.TAB13 And Mizraim begot Ludim, and Anamim, and Lehabim, and Naphtuhim,\n",
      "You see Ludim are from Mitzraim not to be confused with Lud son of Shem (in the far east).\n",
      "Best wishes and keep up the good work.81.103.121.144 \n",
      "\n",
      "Comment  1 :  identity_hate \n",
      " Mate, sound like you are jewish\n",
      "\n",
      "Gayness is in the air \n",
      "\n",
      "Comment  2 :  identity_hate \n",
      " \"Just face the truth: you can't escape it!==\n",
      "User:Arilang1234 didn't edit your foul, slimy racist template, you loser. I suggest that YOU stop pretending that Manchus are ethnically Chinese. How about YOU face the undeniable truth?\n",
      "\n",
      "And how about YOU stop making false accusations about other users?   \n",
      "\n",
      "Following the blocking of the above user, I am very surprised that you haven't been blocked from editing Wikipedia as well given that your Manchu ethnicity template itself (as created by you) is also a blatant violation of Wikipedia policy. 96.9.180.213  \n",
      "\n",
      "Barnstar\n",
      "  The Monkey's Barnstar For pushing forward fringe views on Wikipedia, especially your foul, slimy, racist view that Manchus are ethnically Chinese. You have proven yourself to be more barbaric than this monkey. Here's a banana.\n",
      "\n",
      "Congratulations for acting like a monkey!\n",
      "Wow, so you have managed to earn The Monkey's Barnstar. You must be highly barbaric then. 209.162.35.64  \n",
      "\n",
      "Stop making false accusations\n",
      "Congratulations for calling User 77.182.67.105 the \"\"h word\"\". Well I have news for you: User 77.182.67.105 is not ethnically Chinese. So just face the truth and stop name-calling, you racist Manchu! Otherwise, I will get my meatpuppets to stop you in your tracks!   \n",
      "\n",
      "==\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for category in [\"obscene\", \"threat\", \"insult\", \"identity_hate\"]:\n",
    "    for i in range(2):\n",
    "        print(\"Comment \", i+1, \": \", str(category),\n",
    "              \"\\n\", \n",
    "              df[(df['toxic'] == 0) & (df[category] == 1)][\"comment_text\"].iloc[i], \n",
    "              \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185ae09",
   "metadata": {},
   "source": [
    "✏️ Ummm... these look toxic to me? But I just re-read the challenge rules and I'm expected to classify each of the columns so I'll try not to overthink why these categories are the way they are. I will make an extra column for non-toxic, neutral comments though because in my head that will make the probabilities make sense?\n",
    "\n",
    "#### Adding a non-toxic column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e96b6a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T17:04:10.385794Z",
     "start_time": "2022-12-20T17:04:10.324613Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    143346\n",
       "0     16225\n",
       "Name: non_toxic, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def non_toxic_mapper(x):\n",
    "    if x == 0: \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df[\"non_toxic\"] = df[\"total_score\"].map(non_toxic_mapper)\n",
    "df[\"non_toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d19c09",
   "metadata": {},
   "source": [
    "#### Removing the total_score column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fbc640",
   "metadata": {},
   "source": [
    "This column was only used to explore the data, so I'm dropping it before I start the pre-modelling stages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "85407695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-20T17:09:32.742853Z",
     "start_time": "2022-12-20T17:09:32.718044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>non_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  non_toxic  \n",
       "0             0        0       0       0              0          1  \n",
       "1             0        0       0       0              0          1  \n",
       "2             0        0       0       0              0          1  \n",
       "3             0        0       0       0              0          1  \n",
       "4             0        0       0       0              0          1  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(\"total_score\", axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c606d19",
   "metadata": {},
   "source": [
    "## Pre-Modelling: spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e7540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.847472,
   "position": {
    "height": "40px",
    "left": "1307.78px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
