{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9ebeba",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Importing-packages-&amp;-dataset\" data-toc-modified-id=\"Importing-packages-&amp;-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Importing packages &amp; dataset</a></span></li><li><span><a href=\"#Exploring-the-dataset\" data-toc-modified-id=\"Exploring-the-dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Exploring the dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#General-features\" data-toc-modified-id=\"General-features-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>General features</a></span></li><li><span><a href=\"#Getting-to-know-the-labels\" data-toc-modified-id=\"Getting-to-know-the-labels-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Getting to know the labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#Can-a-comment-be-both-toxic-and-severely-toxic?\" data-toc-modified-id=\"Can-a-comment-be-both-toxic-and-severely-toxic?-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Can a comment be both toxic and severely toxic?</a></span></li><li><span><a href=\"#Do-the-obsene/threat/insult/identity_hate-tags-come-under-the-toxic-umbrella?\" data-toc-modified-id=\"Do-the-obsene/threat/insult/identity_hate-tags-come-under-the-toxic-umbrella?-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Do the obsene/threat/insult/identity_hate tags come under the toxic umbrella?</a></span></li><li><span><a href=\"#Adding-a-non-toxic-column:\" data-toc-modified-id=\"Adding-a-non-toxic-column:-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Adding a non-toxic column:</a></span></li><li><span><a href=\"#Removing-the-total_score-column\" data-toc-modified-id=\"Removing-the-total_score-column-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Removing the total_score column</a></span></li></ul></li></ul></li><li><span><a href=\"#Cleaning-the-comment_text-column\" data-toc-modified-id=\"Cleaning-the-comment_text-column-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cleaning the comment_text column</a></span><ul class=\"toc-item\"><li><span><a href=\"#IP-address\" data-toc-modified-id=\"IP-address-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>IP address</a></span></li><li><span><a href=\"#Date-Time\" data-toc-modified-id=\"Date-Time-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Date Time</a></span></li><li><span><a href=\"#Formatting-characters\" data-toc-modified-id=\"Formatting-characters-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Formatting characters</a></span></li><li><span><a href=\"#Writing-functions-for-future-use-on-unseen-comments-data\" data-toc-modified-id=\"Writing-functions-for-future-use-on-unseen-comments-data-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Writing functions for future use on unseen comments data</a></span></li></ul></li><li><span><a href=\"#Modeling-Trial-1:-Basic-spaCy-Multi-Label-Classification\" data-toc-modified-id=\"Modeling-Trial-1:-Basic-spaCy-Multi-Label-Classification-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modeling Trial 1: Basic spaCy Multi-Label Classification</a></span></li><li><span><a href=\"#Results-&amp;-predictions\" data-toc-modified-id=\"Results-&amp;-predictions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Results &amp; predictions</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe19cc",
   "metadata": {},
   "source": [
    "# Exploring spaCy: Toxicity Levels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e2a5a",
   "metadata": {},
   "source": [
    "**Overview**\n",
    "\n",
    "Using the SpaCy package to explore the [Toxic Comment Classification Challenge](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/overview). \n",
    "\n",
    "- Challenge: build a model that’s capable of detecting different types of of toxicity like **threats, obscenity, insults, and identity-based hate**. \n",
    "- The dataset contains comments from Wikipedia’s talk page edits. \n",
    "- The goal is to help online discussion become more productive and respectful.\n",
    "\n",
    "**Dataset Description**\n",
    "\n",
    "A large number of Wikipedia comments which have been labeled by human raters for toxic behavior. \n",
    "The types of toxicity are:\n",
    "\n",
    "- toxic\n",
    "- severe_toxic\n",
    "- obscene\n",
    "- threat\n",
    "- insult\n",
    "- identity_hate\n",
    "\n",
    "You must create a model which predicts a **probability of each type of toxicity** for each comment.\n",
    "\n",
    "**File descriptions**\n",
    "\n",
    "- train.csv - the training set, contains comments with their binary labels\n",
    "- test.csv - the test set, you must predict the toxicity probabilities for these comments.\n",
    "- sample_submission.csv - a sample submission file in the correct format\n",
    "- test_labels.csv - labels for the test data; value of -1 indicates it was not used for scoring; (Note: file added after competition close!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bef354",
   "metadata": {},
   "source": [
    "## Importing packages & dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffff7c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.188090Z",
     "start_time": "2022-12-21T22:39:39.171513Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set(font_scale=1.5)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82cb910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.285582Z",
     "start_time": "2022-12-21T22:39:39.190965Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/anastasiakuzmich/Desktop/jigsaw-toxic-comment-classification-challenge/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/anastasiakuzmich/Desktop/jigsaw-toxic-comment-classification-challenge/train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataset contains \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m entries with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      4\u001b[0m       \u001b[38;5;241m%\u001b[39m (df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_handles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py:702\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/anastasiakuzmich/Desktop/jigsaw-toxic-comment-classification-challenge/train.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/anastasiakuzmich/Desktop/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "\n",
    "print(\"The dataset contains %s entries with %s features.\" \n",
    "      % (df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d366e9",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ccc41c",
   "metadata": {},
   "source": [
    "### General features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b9473",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.289484Z",
     "start_time": "2022-12-21T22:39:39.289472Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129a454",
   "metadata": {},
   "source": [
    "✏️ Okay, there's no missing values & the data types are fine. Within this dataset there is:\n",
    "\n",
    "1. An id column which might just be easier to drop. \n",
    "2. The comment_text column which contains the content of the comment itself\n",
    "3. The columns indicating the comment's annotation as toxic, severe_toxic, obscene, threat, insult or identity hate. Let's explore these further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba66928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.291567Z",
     "start_time": "2022-12-21T22:39:39.291544Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb210a8",
   "metadata": {},
   "source": [
    "✏️ The labels are binary, so a comment is either of that label, or not of that label. 9% of the comments are toxic, 5% are obscene, 4% are insults, less than 1% are severely toxic, identity theft or a threat. \n",
    "\n",
    "Let's find out if these labels are are mutually exclusive + how many non-toxic comments there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1262ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.293196Z",
     "start_time": "2022-12-21T22:39:39.293184Z"
    }
   },
   "outputs": [],
   "source": [
    "df['total_score'] = (df['toxic'] \n",
    "                     + df[\"severe_toxic\"] \n",
    "                     + df[\"obscene\"] \n",
    "                     + df[\"threat\"]\n",
    "                     + df[\"insult\"]\n",
    "                     + df[\"identity_hate\"])\n",
    "\n",
    "df['total_score'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a9906",
   "metadata": {},
   "source": [
    "✏️ My takeaways at this stage:\n",
    "\n",
    "- 90% of the comments aren't negative. That's good to know, but we are dealing with severe class imbalance...\n",
    "- A good amount of comments ticks several boxes, so the labels are not exclusive. Some tick all 6 somehow? (*How angry do you have to be?*)\n",
    "- The model needs to be capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate. I need to think about how I'll need to restructure the data and what I want my predictors to be.\n",
    "\n",
    "**Next questions to address:**\n",
    "\n",
    "1. Can a comment be both toxic and severely toxic? \n",
    "2. Are toxic & severe toxic the umbrella categories, then obsene/threat/insult/identity_hate their sub-categories? Restructure and see.\n",
    "3. Perhaps at this stage it is worth introducing a non-toxic column? So the model would almost predict whether the comments are toxic vs non-toxic vs severely toxic, then *if* it's toxic then what subcategory of toxic?\n",
    "\n",
    "### Getting to know the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9c86d",
   "metadata": {},
   "source": [
    "#### Can a comment be both toxic and severely toxic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52acc279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.295354Z",
     "start_time": "2022-12-21T22:39:39.295330Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of toxic comments:\", len(df[df['toxic'] == 1]))\n",
    "print(\"Number of severely toxic comments:\", len(df[df['severe_toxic'] == 1]))\n",
    "print(\"Number of severely toxic and toxic comments:\", len(df[(df['toxic'] == 1) & (df['severe_toxic'] == 1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e4b26a",
   "metadata": {},
   "source": [
    "✏️ Yes. All severely toxic comments are also toxic, but not all toxic comments are severe. Perhaps it's worth making them exclusive within the dataframe? Could also do it later on after modelling to see if it would improve the score. \n",
    "\n",
    "#### Do the obsene/threat/insult/identity_hate tags come under the toxic umbrella?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c69bcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.298767Z",
     "start_time": "2022-12-21T22:39:39.298733Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of obsene comments that are not toxic:\",\n",
    "      len(df[(df['toxic'] == 0) & (df['obscene'] == 1)]))\n",
    "\n",
    "print(\"Number of threatening comments that are not toxic:\",\n",
    "      len(df[(df['toxic'] == 0) & (df['threat'] == 1)]))\n",
    "\n",
    "print(\"Number of insulting comments that are not toxic:\",\n",
    "      len(df[(df['toxic'] == 0) & (df['insult'] == 1)]))\n",
    "\n",
    "print(\"Number of identity-hateful comments that are not toxic:\",\n",
    "      len(df[(df['toxic'] == 0) & (df['identity_hate'] == 1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff83f9",
   "metadata": {},
   "source": [
    "✏️ No, apparently they can be mutually exclusive? Which doesn't make complete sense to me. Let's inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fdb9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.300432Z",
     "start_time": "2022-12-21T22:39:39.300413Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for category in [\"obscene\", \"threat\", \"insult\", \"identity_hate\"]:\n",
    "    for i in range(1):\n",
    "        print(\"Comment \", i+1, \": \", str(category),\n",
    "              \"\\n\", \n",
    "              df[(df['toxic'] == 0) & (df[category] == 1)][\"comment_text\"].iloc[i], \n",
    "              \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185ae09",
   "metadata": {},
   "source": [
    "✏️ Ummm... these look toxic to me? But I just re-read the challenge rules and I'm expected to classify each of the columns so I'll try not to overthink why these categories are the way they are. I will make an extra column for non-toxic, neutral comments though because in my head that will make the probabilities make sense?\n",
    "\n",
    "#### Adding a non-toxic column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96b6a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.302474Z",
     "start_time": "2022-12-21T22:39:39.302452Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def non_toxic_mapper(x):\n",
    "    if x == 0: \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df[\"non_toxic\"] = df[\"total_score\"].map(non_toxic_mapper)\n",
    "df[\"non_toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d19c09",
   "metadata": {},
   "source": [
    "#### Removing the total_score column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fbc640",
   "metadata": {},
   "source": [
    "This column was only used to explore the data, so I'm dropping it before I start the pre-modelling stages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85407695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.304269Z",
     "start_time": "2022-12-21T22:39:39.304243Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"total_score\", axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed98dd",
   "metadata": {},
   "source": [
    "## Cleaning the comment_text column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9dae9a",
   "metadata": {},
   "source": [
    "✏️ Having read up on spaCy, it appears that its pipelines work best on natural sentences because that's what its training data looks like. Extensive preprocessing, like removing stop words and lowercasing will ззrently make things worse with spaCy because it uses that information for clues - [StackOverFlow](https://stackoverflow.com/a/70502883) .\n",
    "\n",
    "That said, I will still be removing newlines and formatting characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d1aec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.306428Z",
     "start_time": "2022-12-21T22:39:39.306405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inspecting examples\n",
    "\n",
    "df[\"comment_text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f9caf",
   "metadata": {},
   "source": [
    "✏️ Printing these would make the formatting characters invisible, so I ran the below in individual cells..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa1b78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.308346Z",
     "start_time": "2022-12-21T22:39:39.308322Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df[\"comment_text\"].iloc[1]\n",
    "# df[\"comment_text\"].iloc[5]\n",
    "# df[\"comment_text\"].iloc[10]\n",
    "# df[\"comment_text\"].iloc[20]\n",
    "# df[\"comment_text\"].iloc[21]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999500e1",
   "metadata": {},
   "source": [
    "✏️ \n",
    "\n",
    "**To remove:**\n",
    "\n",
    "Having inspected some of the comments, I decided I will be removing the following features from the data:\n",
    "\n",
    "- IP addresses\n",
    "- Date & Time (Format: + 21:51, January 11, 2016 (UTC))\n",
    "- Newline characters (\\n) & \"\\\\\" separator\n",
    "- Non-breaking spaces (\\xa0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0fa74e",
   "metadata": {},
   "source": [
    "### IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e43b0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.310487Z",
     "start_time": "2022-12-21T22:39:39.310463Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "IpAddressRegex = \"(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\"\n",
    "\n",
    "for i in range(100):\n",
    "    txt = df[\"comment_text\"].iloc[i]\n",
    "    x = re.findall(IpAddressRegex, txt)\n",
    "    if len(x) > 0:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc1307",
   "metadata": {},
   "source": [
    "✏️ The regex works, so I'll use it to clean now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85def46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.312518Z",
     "start_time": "2022-12-21T22:39:39.312501Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"comment_text\"] = df[\"comment_text\"].replace(IpAddressRegex,'', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4246d",
   "metadata": {},
   "source": [
    "### Date Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9f8a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.314017Z",
     "start_time": "2022-12-21T22:39:39.314005Z"
    }
   },
   "outputs": [],
   "source": [
    "DateTimeRegex = \"(\\d{2}\\:\\d{2}\\, [A-Z][a-z]{2,8}\\ \\d{1,2}\\, \\d{4}\\ \\([A-Z]{3}\\))|(\\d{2}\\:\\d{2}\\, \\d{2}\\ [A-Z][a-z]{2}\\ \\d{4}\\ \\([A-Z]{3}\\))\"\n",
    "\n",
    "for i in range(50):\n",
    "    txt = df[\"comment_text\"].iloc[i]\n",
    "    x = re.findall(DateTimeRegex, txt)\n",
    "    if len(x) > 0:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a46d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.315235Z",
     "start_time": "2022-12-21T22:39:39.315222Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"comment_text\"] = df[\"comment_text\"].replace(DateTimeRegex,'', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89063ca3",
   "metadata": {},
   "source": [
    "**Checking for other pattern types:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902a5c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.317437Z",
     "start_time": "2022-12-21T22:39:39.317411Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['comment_text'].str.contains('Jan')][\"comment_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be7846",
   "metadata": {},
   "source": [
    "**Patterns to add:**\n",
    "\n",
    "- 10:36, 5 January 2012\n",
    "- 27 January 2010 (UTC)\n",
    "- \"Semi-protected edit request on \"7 January 2014\n",
    "- 01:29, 30\n",
    "- January 2013 (UTC)\n",
    "\n",
    "✏️ The rest of the dates are mostly mentioned in context. The data should be clear after I add the below formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b929e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.318922Z",
     "start_time": "2022-12-21T22:39:39.318897Z"
    }
   },
   "outputs": [],
   "source": [
    "updated_DateTimeRegex = \"(\\d{2}\\:\\d{2}\\, [A-Z][a-z]{2,8}\\ \\d{1,2}\\, \\d{4}\\ \\([A-Z]{3}\\))|(\\d{2}\\:\\d{2}\\, \\d{2}\\ [A-Z][a-z]{2}\\ \\d{4}\\ \\([A-Z]{3}\\))|(\\d{2}\\:\\d{2}\\, \\d{1,2}\\ [A-Z][a-z]{2,8} \\d{4})|(\\d{1,2}\\ [A-Z][a-z]{2,8}\\ \\d{4}\\ \\([A-Z]{3}\\))|(\\d{1,2}\\ [A-Z][a-z]{1,7}\\ \\d{4})|(\\d{2}\\:\\d{2}\\, \\d{1,2})|([A-Z][a-z]{2,8}\\ \\d{4}\\ \\([A-Z]{3}\\))\"\n",
    "df['comment_text'] = df['comment_text'].replace(updated_DateTimeRegex,'', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379c828",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T15:45:19.065168Z",
     "start_time": "2022-12-21T15:45:19.062135Z"
    }
   },
   "source": [
    "### Formatting characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c058e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.320842Z",
     "start_time": "2022-12-21T22:39:39.320819Z"
    }
   },
   "outputs": [],
   "source": [
    "df['comment_text'] = df[\"comment_text\"].replace('\\\\n', ' ', regex=True)\n",
    "df['comment_text'] = df['comment_text'].replace(r'\\\\', ' ', regex=True)\n",
    "df['comment_text'] = df['comment_text'].replace(u'\\xa0', u' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f24e5b",
   "metadata": {},
   "source": [
    "### Writing functions for future use on unseen comments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffeec13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.322916Z",
     "start_time": "2022-12-21T22:39:39.322886Z"
    }
   },
   "outputs": [],
   "source": [
    "def non_toxic_mapper(x):\n",
    "    \n",
    "    \"\"\"Maps the non-toxic column based on the total score column.\"\"\"\n",
    "    \n",
    "    if x == 0: \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def add_non_toxic_column(df):\n",
    "    \n",
    "    \"\"\"Adds a non-toxic column.\"\"\"\n",
    "    \n",
    "    df['total_score'] = (df['toxic'] + df[\"severe_toxic\"] \n",
    "                         + df[\"obscene\"] + df[\"threat\"]\n",
    "                         + df[\"insult\"] + df[\"identity_hate\"])\n",
    "\n",
    "    df[\"non_toxic\"] = df[\"total_score\"].map(non_toxic_mapper)\n",
    "    df = df.drop(\"total_score\", axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_comments_column(df):\n",
    "    \n",
    "    \"\"\"Cleans the comments column.\"\"\"\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    IpAddressRegex = \"(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\"\n",
    "    DateTimeRegex = \"(\\d{2}\\:\\d{2}\\, [A-Z][a-z]{2,8}\\ \\d{1,2}\\, \\d{4}\\ \\([A-Z]{3}\\))|(\\d{2}\\:\\d{2}\\, \\d{2}\\ [A-Z][a-z]{2}\\ \\d{4}\\ \\([A-Z]{3}\\))|(\\d{2}\\:\\d{2}\\, \\d{1,2}\\ [A-Z][a-z]{2,8} \\d{4})|(\\d{1,2}\\ [A-Z][a-z]{2,8}\\ \\d{4}\\ \\([A-Z]{3}\\))|(\\d{1,2}\\ [A-Z][a-z]{1,7}\\ \\d{4})|(\\d{2}\\:\\d{2}\\, \\d{1,2})|([A-Z][a-z]{2,8}\\ \\d{4}\\ \\([A-Z]{3}\\))\"\n",
    "    \n",
    "    features_to_remove = [IpAddressRegex,\n",
    "                          DateTimeRegex,\n",
    "                          '\\\\n', r'\\\\']\n",
    "    \n",
    "    for feature in features_to_remove:\n",
    "        df[\"comment_text\"] = df[\"comment_text\"].replace(feature,' ', regex=True)\n",
    " \n",
    "    df['comment_text'] = df['comment_text'].replace(u'\\xa0', u' ')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee63e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T16:01:14.152954Z",
     "start_time": "2022-12-21T16:01:14.098755Z"
    }
   },
   "source": [
    "## Modeling Trial 1: Basic spaCy Multi-Label Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d27f5fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6edf0b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.324923Z",
     "start_time": "2022-12-21T22:39:39.324903Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d189af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.330199Z",
     "start_time": "2022-12-21T22:39:39.330171Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df[['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate', 'non_toxic']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5d5cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.332071Z",
     "start_time": "2022-12-21T22:39:39.332046Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = list(y.columns)\n",
    "y = y.to_dict(\"index\")\n",
    "\n",
    "dataset = list(zip(df[\"comment_text\"], \n",
    "               [{'cats':cats} for cats in y.values()]))\n",
    "\n",
    "print(dataset[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a6f9a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56456fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.333761Z",
     "start_time": "2022-12-21T22:39:39.333734Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(dataset, \n",
    "                                         train_size=0.8, \n",
    "                                         random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0d93de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.335388Z",
     "start_time": "2022-12-21T22:39:39.335368Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(dataset, \n",
    "                                         train_size=0.8, \n",
    "                                         random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3987dd03",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7f96d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.337184Z",
     "start_time": "2022-12-21T22:39:39.337151Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "from spacy.pipeline.textcat_multilabel import DEFAULT_MULTI_TEXTCAT_MODEL\n",
    "\n",
    "config = {\n",
    "   \"threshold\": 0.5,\n",
    "   \"model\": DEFAULT_MULTI_TEXTCAT_MODEL,\n",
    "}\n",
    "\n",
    "textcat = nlp.add_pipe(\"textcat_multilabel\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d59f80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cdb136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.338895Z",
     "start_time": "2022-12-21T22:39:39.338880Z"
    }
   },
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    textcat.add_label(label)\n",
    "    \n",
    "textcat.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bf3556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.357266Z",
     "start_time": "2022-12-21T22:39:39.342993Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[38;5;241m.\u001b[39mbegin_training()\n\u001b[1;32m      2\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = nlp.begin_training()\n",
    "iterations = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa96936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:39:39.359679Z",
     "start_time": "2022-12-21T22:39:39.359667Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import Example\n",
    "\n",
    "with nlp.select_pipes(enable=\"textcat_multilabel\"):\n",
    "    for j in range(iterations):\n",
    "        losses = {}\n",
    "        k = 0\n",
    "        batches = minibatch(train_data, size = compounding(4.,32.,1.001))\n",
    "        for batch in batches:\n",
    "            text, annotations = zip(*batch)\n",
    "            example = []\n",
    "            for i in range(len(text)):\n",
    "                doc = nlp.make_doc(text[i])\n",
    "                example.append(Example.from_dict(doc, annotations[i]))\n",
    "            nlp.update(example, sgd=optimizer, drop=0.2, losses = losses)\n",
    "            print('Batch No: {} Loss = {}'.format(k, round(losses['textcat_multilabel'])))\n",
    "            k += 1\n",
    "        print(\"\\n\\n Completed Iterations : {} \".format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25404e10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T21:54:06.401586Z",
     "start_time": "2022-12-21T21:54:06.393350Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Okay so no one's gonna address this? Guess that no one editing this page cares about accuracy.\",\n",
       "  {'cats': {'toxic': 0,\n",
       "    'severe_toxic': 0,\n",
       "    'obscene': 0,\n",
       "    'threat': 0,\n",
       "    'insult': 0,\n",
       "    'identity_hate': 0,\n",
       "    'non_toxic': 1}}),\n",
       " ('\"   In regards to wishful thinking   \"\"Due to Leuchter\\'s ignorance of the large disparity between the amounts of cyanide necessary to kill humans and lice, instead of disproving the homicidal use of gas chambers, the small amounts of cyanide which Leuchter detected actually tended to confirm it.[8]\"\"  It doesn\\'t explain how it tended to confirm it, also this whole sentence is presented as fact like everything else in this biased article. Thus I\\'m assuming it\\'s wishful thinking and only here to discredit Leutcher.   \"',\n",
       "  {'cats': {'toxic': 0,\n",
       "    'severe_toxic': 0,\n",
       "    'obscene': 0,\n",
       "    'threat': 0,\n",
       "    'insult': 0,\n",
       "    'identity_hate': 0,\n",
       "    'non_toxic': 1}}),\n",
       " (\"Ok, so put the pictures somewhere in the article. Beirut cannot be the main picture because it is biased and misportrays events. It makes it appear that Israel planned this attack in the first place. The main picture should show Hezbollah firing missiles because after all Hezbollah started this conflict. If Hezbollah hadn't started it, Israel would NOT have to launch this operation.\",\n",
       "  {'cats': {'toxic': 0,\n",
       "    'severe_toxic': 0,\n",
       "    'obscene': 0,\n",
       "    'threat': 0,\n",
       "    'insult': 0,\n",
       "    'identity_hate': 0,\n",
       "    'non_toxic': 1}}),\n",
       " ('|I apologise for making that remark to Sidaway.  In return, perhaps he could be a little more reasonable in not effectively deleting material from a talk page.',\n",
       "  {'cats': {'toxic': 0,\n",
       "    'severe_toxic': 0,\n",
       "    'obscene': 0,\n",
       "    'threat': 0,\n",
       "    'insult': 0,\n",
       "    'identity_hate': 0,\n",
       "    'non_toxic': 1}}),\n",
       " ('\"  At some point in the article\\'s history, the idea expressed by this passage was followed by some discussion of airflow on both sides of the wing and the point made that some explanations only involve air being deflected by the bottom of the wing. (sometimes called \"\"bullet theroy\"\" or \"\"skipping stone theory\"\").  This was accompanied by a graph showing the pressure distribution along the top and bottom of a wing where the pressure difference along the top was substantially larger than along the bottom.  At some point this was excised, whether by accident or not.  Which is to say that your interpretation of the intent is correct.  I can see where what is actually written may be interpreted differently than what was meant.  A suggestion for how to reword would be welcome.  I\\'ll take a look at earlier versions and see if we edited something out that shouldn\\'t have been.  Personally, I don\\'t read the passage as a statement of cause and effect but I can see how someone might interpret it that way.    \"',\n",
       "  {'cats': {'toxic': 0,\n",
       "    'severe_toxic': 0,\n",
       "    'obscene': 0,\n",
       "    'threat': 0,\n",
       "    'insult': 0,\n",
       "    'identity_hate': 0,\n",
       "    'non_toxic': 1}})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0481d57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T21:53:47.982973Z",
     "start_time": "2022-12-21T21:53:47.961913Z"
    }
   },
   "outputs": [],
   "source": [
    "train_comments, test_comments = train_test_split(df[\"comment_text\"],\n",
    "                                                 train_size=0.8,\n",
    "                                                 random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2853a13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T21:56:18.543100Z",
     "start_time": "2022-12-21T21:55:59.504781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "\n",
    "texts = list(train_comments)\n",
    "docs = [nlp.tokenizer(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87f5127",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T22:36:57.218359Z",
     "start_time": "2022-12-21T22:36:56.721784Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Use textcat to get the scores for each doc\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m textcat \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[38;5;241m.\u001b[39mget_pipe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtextcat_multilabel\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m scores, _ \u001b[38;5;241m=\u001b[39m textcat\u001b[38;5;241m.\u001b[39mpredict(docs)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# Use textcat to get the scores for each doc\n",
    "\n",
    "textcat = nlp.get_pipe('textcat_multilabel')\n",
    "scores, _ = textcat.predict(docs)\n",
    "print(scores[0:5])\n",
    "\n",
    "# The kernel died ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a2d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3dfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ff2f4c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T19:49:20.732962Z",
     "start_time": "2022-12-21T19:49:20.262652Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.to_disk('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4fc5aa18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T20:27:52.548418Z",
     "start_time": "2022-12-21T20:27:51.980645Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('train.npy', train_data, allow_pickle=True)\n",
    "np.save('test.npy', test_data, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b54016",
   "metadata": {},
   "source": [
    "## Results & predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc43522e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T21:15:30.373378Z",
     "start_time": "2022-12-21T21:15:29.980340Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = nlp.from_disk('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4196be96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T21:15:55.834214Z",
     "start_time": "2022-12-21T21:15:55.819544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f91ddb0d670>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd203f44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T21:07:44.913441Z",
     "start_time": "2022-12-21T21:07:44.345510Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data = np.load(\"train.npy\", allow_pickle=True)\n",
    "train_data = train_data.tolist()\n",
    "\n",
    "test_data = np.load(\"test.npy\", allow_pickle=True)\n",
    "test_data = test_data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d28b994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-21T21:09:43.630342Z",
     "start_time": "2022-12-21T21:09:43.270637Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[43mmy_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/spacy/language.py:984\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    967\u001b[0m     text: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    970\u001b[0m     component_cfg: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    971\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[1;32m    972\u001b[0m     \u001b[38;5;124;03m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m    is preserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;124;03m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 984\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m component_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         component_cfg \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/spacy/language.py:1066\u001b[0m, in \u001b[0;36mLanguage.make_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length:\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1064\u001b[0m         Errors\u001b[38;5;241m.\u001b[39mE088\u001b[38;5;241m.\u001b[39mformat(length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(text), max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length)\n\u001b[1;32m   1065\u001b[0m     )\n\u001b[0;32m-> 1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got list)"
     ]
    }
   ],
   "source": [
    "processed = my_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e61c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f5b7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e4d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.847472,
   "position": {
    "height": "756.836px",
    "left": "1307.77px",
    "right": "20px",
    "top": "121px",
    "width": "476.006px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
